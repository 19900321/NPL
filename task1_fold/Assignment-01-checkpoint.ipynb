{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lesson-01 Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`各位同学大家好，欢迎各位开始学习我们的人工智能课程。这门课程假设大家不具备机器学习和人工智能的知识，但是希望大家具备初级的Python编程能力。根据往期同学的实际反馈，我们课程的完结之后 能力能够超过80%的计算机人工智能/深度学习方向的硕士生的能力。`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 本次作业的内容"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 复现课堂代码\n",
    "\n",
    "在本部分，你需要参照我们给大家的GitHub地址里边的课堂代码，结合课堂内容，复现内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 请回答以下问题\n",
    "\n",
    "回答以下问题，并将问题发送至 mqgao@kaikeba.com中：\n",
    "```\n",
    "    2.1. what do you want to acquire in this course？\n",
    "    The proper ways how to process Natural languag. Some more advanced programming skills.\n",
    "    \n",
    "    2.2. what problems do you want to solve？\n",
    "    The want to learn the prescription rules in tarditional medicine.\n",
    "    \n",
    "    2.3. what’s the advantages you have to finish you goal?\n",
    "    I have the experience of coding. I have more time.\n",
    "    \n",
    "    2.4. what’s the disadvantages you need to overcome to finish you goal?\n",
    "    I am not a students from compúter science and thus do not have too much experience of project. Some programmer is very simple and silly.\n",
    "    \n",
    "    2.5. How will you plan to study in this course period?\n",
    "    Listen to lectures and finish the task. Try best to allpied the method to my won project.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 如何提交\n",
    "代码 + 此 jupyter 相关，提交至自己的 github 中(**所以请务必把GitHub按照班主任要求录入在Trello中**)；\n",
    "第2问，请提交至mqgao@kaikeba.com邮箱。\n",
    "#### 4. 作业截止时间\n",
    "此次作业截止时间为 2019.7.6日"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. 完成以下问答和编程练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {use AI to predict or generalize the behavior of customers from their digital footprints in order to target them with personalized promotions or build customer personas automatically.,help of AI correctly determined the accurate dose of drugs to give to organ patients, self-driving cars}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {We use github to save our files and record the changes of code so that we can share them and work together easily. Juper is a good way to show the result of code. Pycharm is a good choice for project organization.}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:A probability model is a mathematical representation of a random phenomenon. It is defined by its sample space, events within the sample space, and probabilities associated with each event.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Ans: Find significant expression genes(biomaker of disease) in medicine. The gSports game for bat Strategies.  Weather prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:As we can not know whether a futur event will happen or not. However, we can give a probility. The difficult points for programming based on parsing and pattern match is to give a powerful rules which can deal with variable situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:A statistical language model is a probability distribution over sequences of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:siri of iphone, robot answer box of websites, google search, Protein sequencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: a type of probabilistic language model for predicting the next one item in a sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:\n",
    "advantage: simplicity and scalability.\n",
    "disadvantage: n-gram models are not designed to model linguistic knowledge as such, and make no claims to being (even potentially) complete models of linguistic knowledge; instead, they are used in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:a type of probabilistic language model for predicting the next 2 item in a sequence. words are modeled such that each 2-gram is composed of 2 words. When used for language modeling, independence assumptions are made so that each word depends only on the last 1 words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如何生成句子是一个很经典的问题，从1940s开始，图灵提出机器智能的时候，就使用的是人类能不能流畅和计算机进行对话。和计算机对话的一个前提是，计算机能够生成语言。\n",
    "\n",
    "计算机如何能生成语言是一个经典但是又很复杂的问题。 我们课程上为大家介绍的是一种基于规则（Rule Based）的生成方法。该方法虽然提出的时间早，但是现在依然在很多地方能够大显身手。值得说明的是，现在很多很实用的算法，都是很久之前提出的，例如，二分查找提出与1940s, Dijstra算法提出于1960s 等等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在著名的电视剧，电影《西部世界》中，这些机器人们语言生成的方法就是使用的SyntaxTree生成语言的方法。\n",
    "\n",
    "> \n",
    ">\n",
    "\n",
    "![WstWorld](https://timgsa.baidu.com/timg?image&quality=80&size=b10000_10000&sec=1561818705&di=95ca9ff2ff37fcb88ae47b82c7079feb&src=http://s7.sinaimg.cn/mw690/006BKUGwzy75VK46FMi66&690)\n",
    "\n",
    "> \n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这一部分，需要各位同学首先定义自己的语言。 大家可以先想一个应用场景，然后在这个场景下，定义语法。例如：\n",
    "\n",
    "在西部世界里，一个”人类“的语言可以定义为：\n",
    "``` \n",
    "human = \"\"\"\n",
    "human = 自己 寻找 活动\n",
    "自己 = 我 | 俺 | 我们 \n",
    "寻找 = 看看 | 找找 | 想找点\n",
    "活动 = 乐子 | 玩的\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "一个“接待员”的语言可以定义为\n",
    "```\n",
    "host = \"\"\"\n",
    "host = 寒暄 报数 询问 业务相关 结尾 \n",
    "报数 = 我是 数字 号 ,\n",
    "数字 = 单个数字 | 数字 单个数字 \n",
    "单个数字 = 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 \n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 先生 | 女士 | 小朋友\n",
    "打招呼 = 你好 | 您好 \n",
    "询问 = 请问你要 | 您需要\n",
    "业务相关 = 玩玩 具体业务\n",
    "玩玩 = 耍一耍 | 玩一玩\n",
    "具体业务 = 喝酒 | 打牌 | 打猎 | 赌博\n",
    "结尾 = 吗？\"\"\"\n",
    "\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请定义你自己的语法: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_er = '''\n",
    "question = 介绍  寒暄 ,  询问 问词 种类 啊?\n",
    "介绍 = 我是 名字 ,\n",
    "名字 = 引引 | 高老师 | 助教\n",
    "寒暄 = 称谓 打招呼 | 打招呼\n",
    "称谓 = 人称 ,\n",
    "人称 = 美女 | 帅哥 | 亲爱的\n",
    "打招呼 = 你好 | 别来无恙  |  最近在忙啥\n",
    "询问 = 请问你喜欢 | 请问你讨厌\n",
    "问词 = 哪种 | 哪类 \n",
    "种类 = 乐器 | 舞蹈 | 音乐 | 编程语言\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_er = '''\n",
    "answer = 人称 动词 种类 ！ | 拒绝回答 !\n",
    "人称 = 本菇凉 | 本人 | 本帅哥 | 俺\n",
    "动词 = 喜欢 | 很喜欢 | 非常喜爱 | 讨厌 | 很讨厌 | 非常讨厌\n",
    "种类 = 乐器 | 舞蹈 | 音乐 | 编程语言 \n",
    "乐器 = 吉他 | 钢琴 | 琵琶 |手风琴 | 二胡\n",
    "舞蹈 = salsa | 芭蕾 | 现代舞 |地板舞 | 爵士 | 甩手舞\n",
    "音乐 = 欧美的音乐 | 乡村的音乐 | bibox \n",
    "编程语言 = python | java | c++ |matlab | R\n",
    "拒绝回答 =  无可奉告 | 对不起， 我不想说话 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammar(grammer_str, split = '=',line_split = '\\n'):          \n",
    "    grammer = {}                                                          \n",
    "    for line in grammer_str.split(line_split):                            \n",
    "        if not line.strip(): continue                                     \n",
    "        exp, stmt = line.split(split)                                     \n",
    "        grammer[exp.strip()] = [i.split() for i in stmt.split('|')]       \n",
    "    return grammer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "choice = random.choice  \n",
    "def generate(gram,target): \n",
    "    if target not in gram: return target                                                                                                                            \n",
    "    expand = [generate(gram, t) for t in choice(gram[target])]                    \n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expand if e != 'null'])     \n",
    "                                                                                  \n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramquestion = create_grammar(question_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'我是高老师,帅哥,别来无恙,请问你喜欢哪种音乐啊?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=gramquestion, target='question') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gramanswer = create_grammar(answer_er)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'无可奉告!'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate(gram=gramanswer, target='answer') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['俺非常讨厌c++！', '对不起，我不想说话!', '无可奉告!']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_s = [generate(gram=gramanswer, target='answer') for i in range(3)]\n",
    "sen_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(gram,target,n):                                    \n",
    "    sen_s = [generate(gram=gram, target=target) for i in range(n)]\n",
    "    phase =  ' '.join(sen_s)                       \n",
    "    return phase          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'对不起，我不想说话! 本菇凉喜欢琵琶！ 无可奉告!'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_n(gram=gramanswer, target='answer', n = 3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的`prob_2`函数，我们更换一个文本数据源，获得新的Language Model:\n",
    "\n",
    "1. 下载文本数据集（你可以在以下数据集中任选一个，也可以两个都使用）\n",
    "    + 可选数据集1，保险行业问询对话集： https://github.com/Computing-Intelligence/insuranceqa-corpus-zh/raw/release/corpus/pool/train.txt.gz\n",
    "    + 可选数据集2：豆瓣评论数据集：https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv\n",
    "2. 修改代码，获得新的**2-gram**语言模型\n",
    "    + 进行文本清洗，获得所有的纯文本\n",
    "    + 将这些文本进行切词\n",
    "    + 送入之前定义的语言模型中，判断文本的合理程度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd \n",
    "import jieba        \n",
    "url = 'https://github.com/Computing-Intelligence/datasource/raw/master/movie_comments.csv' \n",
    "html_2 = requests.get(url).content                                                       \n",
    "responseStr_2 = html_2.decode(\"utf-8\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "responseStr_list = responseStr_2.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#进行文本清洗，获得所有的纯文本\n",
    "import re\n",
    "def token(string):                                       \n",
    "    # we will learn the regular expression next course. \n",
    "    text_get = ''.join (re.findall('\\w+', string))\n",
    "    return text_get     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将这些文本进行切词\n",
    "def cut(string): return list(jieba.cut(token(string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add, mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "item = reduce(add,[cut(i) for i in responseStr_list[1:5000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#送入之前定义的语言模型中，判断文本的合理程度\n",
    "TOKEN = item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 8177),\n",
       " ('了', 2818),\n",
       " ('是', 1821),\n",
       " ('我', 1352),\n",
       " ('4', 1331),\n",
       " ('5', 1244),\n",
       " ('3', 1130),\n",
       " ('2', 1100),\n",
       " ('在', 1050),\n",
       " ('都', 1028),\n",
       " ('和', 1026),\n",
       " ('1', 901),\n",
       " ('电影', 857),\n",
       " ('看', 799),\n",
       " ('也', 763),\n",
       " ('不', 747),\n",
       " ('很', 747),\n",
       " ('你', 720),\n",
       " ('有', 713),\n",
       " ('就', 692),\n",
       " ('人', 674),\n",
       " ('狼', 646),\n",
       " ('ン', 520),\n",
       " ('好', 511),\n",
       " ('还', 510),\n",
       " ('这', 485),\n",
       " ('故事', 470),\n",
       " ('但', 470),\n",
       " ('啊', 450),\n",
       " ('一个', 446),\n",
       " ('神偷', 406),\n",
       " ('还是', 391),\n",
       " ('没有', 390),\n",
       " ('让', 359),\n",
       " ('来', 348),\n",
       " ('湄公河', 346),\n",
       " ('行动', 343),\n",
       " ('战狼', 339),\n",
       " ('就是', 329),\n",
       " ('时代', 328),\n",
       " ('给', 323),\n",
       " ('说', 320),\n",
       " ('一部', 298),\n",
       " ('到', 295),\n",
       " ('剧情', 295),\n",
       " ('得', 294),\n",
       " ('又', 283),\n",
       " ('他', 280),\n",
       " ('与', 274),\n",
       " ('剧场版', 273),\n",
       " ('当', 271),\n",
       " ('被', 268),\n",
       " ('太', 267),\n",
       " ('吧', 266),\n",
       " ('上', 264),\n",
       " ('能', 263),\n",
       " ('福音战士', 262),\n",
       " ('ヴ', 259),\n",
       " ('ァ', 259),\n",
       " ('リ', 259),\n",
       " ('ゲ', 259),\n",
       " ('最后', 258),\n",
       " ('版', 257),\n",
       " ('真的', 257),\n",
       " ('小', 256),\n",
       " ('没', 252),\n",
       " ('为', 252),\n",
       " ('可以', 250),\n",
       " ('多', 248),\n",
       " ('什么', 246),\n",
       " ('最', 246),\n",
       " ('对', 245),\n",
       " ('岁月', 245),\n",
       " ('这个', 245),\n",
       " ('拍', 243),\n",
       " ('世界', 242),\n",
       " ('不是', 239),\n",
       " ('Air', 238),\n",
       " ('要', 237),\n",
       " ('幸福', 228),\n",
       " ('月', 227),\n",
       " ('觉得', 227),\n",
       " ('喜欢', 222),\n",
       " ('金蝉脱壳', 218),\n",
       " ('把', 215),\n",
       " ('金刚', 214),\n",
       " ('爱', 213),\n",
       " ('敲门', 210),\n",
       " ('演技', 209),\n",
       " ('EscapePlan', 207),\n",
       " ('李雷', 207),\n",
       " ('歲', 207),\n",
       " ('去', 207),\n",
       " ('自己', 205),\n",
       " ('感觉', 204),\n",
       " ('杀破', 200),\n",
       " ('不错', 199),\n",
       " ('韩梅梅', 197),\n",
       " ('导演', 196),\n",
       " ('救赎', 195)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = [str(t) for t in TOKEN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('狼2', 383),\n",
       " ('湄公河行动', 326),\n",
       " ('ゲリ', 259),\n",
       " ('ヴァ', 259),\n",
       " ('ンゲ', 259),\n",
       " ('ァン', 259),\n",
       " ('的故事', 253),\n",
       " ('金蝉脱壳EscapePlan', 207),\n",
       " ('歲月', 207),\n",
       " ('金刚狼', 206),\n",
       " ('岁月神偷', 206),\n",
       " ('来敲门', 204),\n",
       " ('幸福来', 202),\n",
       " ('神偷歲', 201),\n",
       " ('杀破狼', 200),\n",
       " ('当幸福', 200),\n",
       " ('的电影', 199),\n",
       " ('2殺破', 194),\n",
       " ('月神偷', 194),\n",
       " ('殺破狼', 194),\n",
       " ('李雷和', 192),\n",
       " ('的救赎', 187),\n",
       " ('和韩梅梅', 185),\n",
       " ('肖申克的', 184),\n",
       " ('敲门ThePursuitofHappyness', 179),\n",
       " ('救赎TheShawshankRedemption', 170),\n",
       " ('看的', 169),\n",
       " ('狼3', 164),\n",
       " ('殊死一战', 162),\n",
       " ('贫民窟的', 162),\n",
       " ('的百万富翁', 161),\n",
       " ('修罗战场', 161),\n",
       " ('心灵捕手', 161),\n",
       " ('3殊死', 160),\n",
       " ('绣春刀II', 159),\n",
       " ('忠犬八公的', 159),\n",
       " ('II修罗', 159),\n",
       " ('小时代', 157),\n",
       " ('都是', 155),\n",
       " ('故事HachiADogsTale', 155),\n",
       " ('世界中心', 149),\n",
       " ('中心呼唤', 148),\n",
       " ('在世界', 147),\n",
       " ('百万富翁SlumdogMillionaire', 146),\n",
       " ('让人', 143),\n",
       " ('不可及', 143),\n",
       " ('捕手GoodWillHunting', 142),\n",
       " ('触不可', 142),\n",
       " ('新剧场版', 141),\n",
       " ('战狼2', 141),\n",
       " ('一战Logan', 140),\n",
       " ('ン新劇場', 139),\n",
       " ('ヱヴ', 139),\n",
       " ('福音战士新', 139),\n",
       " ('ヲン', 139),\n",
       " ('リヲ', 139),\n",
       " ('时代3', 138),\n",
       " ('及Intouchables', 134),\n",
       " ('3刺金', 132),\n",
       " ('刺金时代', 132),\n",
       " ('智取威虎山', 128),\n",
       " ('为你', 123),\n",
       " ('新世纪福音战士', 122),\n",
       " ('真心为', 122),\n",
       " ('荒岛余生', 120),\n",
       " ('リオ', 120),\n",
       " ('オン', 120),\n",
       " ('エヴ', 120),\n",
       " ('也是', 120),\n",
       " ('的时候', 119),\n",
       " ('福音战士剧场版', 119),\n",
       " ('看了', 119),\n",
       " ('傻大闹宝莱坞', 118),\n",
       " ('を君', 118),\n",
       " ('ころ', 118),\n",
       " ('剧场版Air', 118),\n",
       " ('ろを', 118),\n",
       " ('神奇女侠', 118),\n",
       " ('劇場版', 118),\n",
       " ('新世紀エ', 118),\n",
       " ('三傻大闹', 118),\n",
       " ('ン劇場', 118),\n",
       " ('Air真心', 118),\n",
       " ('你新世紀', 118),\n",
       " ('まご', 118),\n",
       " ('版Air', 118),\n",
       " ('Airま', 118),\n",
       " ('君に', 118),\n",
       " ('ごこ', 118),\n",
       " ('呼唤爱', 116),\n",
       " ('的人', 114),\n",
       " ('宝莱坞3Idiots', 111),\n",
       " ('了5', 107),\n",
       " ('了1', 106),\n",
       " ('何以笙箫', 105),\n",
       " ('余生CastAway', 105),\n",
       " ('的是', 103),\n",
       " ('的演讲', 101),\n",
       " ('国王的', 101),\n",
       " ('还在', 100)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count_2.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probablity(sentence):\n",
    "    words = cut(sentence)\n",
    "    \n",
    "    sentence_pro = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_ = words[i+1]\n",
    "        \n",
    "        probability = prob_2(word, next_)\n",
    "        \n",
    "        sentence_pro *= probability\n",
    "    \n",
    "    return sentence_pro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "电影吴京差 is more possible\n",
      "---- 吴京电影拍得好 with probility 3.25847855289814e-16\n",
      "---- 电影吴京差 with probility 6.8813179100061245e-06\n",
      "女主角漂亮 is more possible\n",
      "---- 女猪脚漂亮 with probility 4.735253617857106e-11\n",
      "---- 女主角漂亮 with probility 6.8813179100061245e-06\n"
     ]
    }
   ],
   "source": [
    "need_compared = ['吴京电影拍得好 电影吴京差',\n",
    "                '女猪脚漂亮 女主角漂亮']\n",
    "for s in need_compared:\n",
    "    s1, s2 = s.split()\n",
    "    p1, p2 = get_probablity(s1), get_probablity(s2)\n",
    "    \n",
    "    better = s1 if p1 > p2 else s2\n",
    "    \n",
    "    print('{} is more possible'.format(better))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s1, p1))\n",
    "    print('-'*4 + ' {} with probility {}'.format(s2, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. 获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成**n**个句子，并能选择一个最合理的句子: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 5]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([1, 3, 5, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数接受一个参数key，这个参数接受一个函数作为输入，例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (2, 5), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第0个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, 0), (1, 4), (4, 4), (2, 5)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 5), (1, 4), (4, 4), (5, 0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted([(2, 5), (1, 4), (5, 0), (4, 4)], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "能够让list按照第1个元素进行排序, 但是是递减的顺序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(gram, target, n): # you code here\n",
    "    sentences = generate_n(gram, target, n).split() \n",
    "    p_value = [(get_probablity(s1),s) for s in sentences]\n",
    "    p_value_sorted = sorted(p_value, key=lambda x: x[1], reverse=True)\n",
    "    print('The best sentence is {} and it is with probility {}'.format(str(p_value_sorted[0][1]),p_value_sorted[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best sentence is 我是高老师,美女,别来无恙,请问你喜欢哪类编程语言啊? and it is with probility 4.735253617857106e-11\n"
     ]
    }
   ],
   "source": [
    "generate_best(gram=gramquestion, target='question', n = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 这个模型有什么问题？ 你准备如何提升？ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: 这个probility model 模型是用电影评论建立的， 而我的语言生成模型用的是日常兴趣爱好的问答。 并没有现实意义。应该针对probility model 模型， 以及实际意义， 建立grammer  规则。 同时，probility model 模型 的建立需要很长时间，应该保存，以备随时使用。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 以下内容为可选部分，对于绝大多数同学，能完成以上的项目已经很优秀了，下边的内容如果你还有精力可以试试，但不是必须的。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. (Optional) 完成基于Pattern Match的语句问答\n",
    "> 我们的GitHub仓库中，有一个assignment-01-optional-pattern-match，这个难度较大，感兴趣的同学可以挑战一下。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 5. (Optional) 完成阿兰图灵机器智能原始论文的阅读\n",
    "1. 请阅读阿兰图灵关于机器智能的原始论文：https://github.com/Computing-Intelligence/References/blob/master/AI%20%26%20Machine%20Learning/Computer%20Machinery%20and%20Intelligence.pdf \n",
    "2. 并按照GitHub仓库中的论文阅读模板，填写完毕后发送给我: mqgao@kaikeba.com 谢谢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "各位同学，我们已经完成了自己的第一个AI模型，大家对人工智能可能已经有了一些感觉，人工智能的核心就是，我们如何设计一个模型、程序，在外部的输入变化的时候，我们的程序不变，依然能够解决问题。人工智能是一个很大的领域，目前大家所熟知的深度学习只是其中一小部分，之后也肯定会有更多的方法提出来，但是大家知道人工智能的目标，就知道了之后进步的方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后，希望大家对AI不要有恐惧感，这个并不难，大家加油！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1561828422005&di=48d19c16afb6acc9180183a6116088ac&imgtype=0&src=http%3A%2F%2Fb-ssl.duitang.com%2Fuploads%2Fitem%2F201807%2F28%2F20180728150843_BECNF.thumb.224_0.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
